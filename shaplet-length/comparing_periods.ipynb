{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between different users\n",
    "\n",
    "This notebook is used to compare and analyze different methods of determining the length of a shaplet using the peak method.\n",
    "\n",
    "Assumptions\n",
    "* Each walking shaplet has a single peak far greater than the rest.\n",
    "\n",
    "TODO\n",
    "* Improve method to accept a shaplet with n peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "import peakutils\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Detection\n",
    "This peak detection algorithm calculates peaks based on a given timeseries array and a threshold.  Refer to the [documentation](http://pythonhosted.org/PeakUtils/).  This method uses the peak detection algorithm to find the average distance between peaks.  If no peaks are found, the method returns nan.  \n",
    "\n",
    "**Accuracy of the peak detection algorithm is assumed but not verified.  We should replace this with our custom peak detection algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_period(df, threshold, axis='x'):\n",
    "    indexes = peakutils.indexes(df[axis].values, thres=threshold, min_dist=10)\n",
    "    indexes = pd.Series(indexes)\n",
    "    #peaks = df.iloc[indexes]\n",
    "    #plt.close()\n",
    "    #plt.plot(df['x'])\n",
    "    #plt.plot(peaks['x'], 'r+')\n",
    "    if indexes.index.size != 0:\n",
    "        diff = indexes.drop(0) - indexes.shift(1).drop(0)\n",
    "        return diff.mean()\n",
    "    return float('nan')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users who have data on walking: ['/102', '/103', '/107', '/110', '/116', '/118', '/121', '/122', '/125', '/131', '/133', '/140', '/143', '/144', '/148', '/149', '/153', '/159', '/161', '/166', '/171', '/174', '/179', '/181', '/182', '/184', '/188', '/189', '/192']\n",
    "\n",
    "**Make sure your data file is in the right location on your local machine.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "walking116 = pd.read_csv('../../data/116/13_treadmill_3mph_0%.csv', names=[\"tick\", \"timestamp\",\n",
    "                                             \"activity\", \"x\", \"y\",\n",
    "                                             \"z\", \"user\"], index_col=False)\n",
    "walking125 = pd.read_csv('../../data/125/13_treadmill_3mph_0%.csv', names=[\"tick\", \"timestamp\",\n",
    "                                             \"activity\", \"x\", \"y\",\n",
    "                                             \"z\", \"user\"], index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "I trimmed the beggining and end of each timeseries due to bogus values.  Points were chosen visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "walking116 = walking116.iloc[2800:21000]\n",
    "walking125 = walking125.iloc[2500:20000]\n",
    "walking116 = walking116.reset_index()\n",
    "walking125 = walking125.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Peak Detection\n",
    "Our parameters are the time series to search, the window size, and the threshold to examine.  To improve accuracy, we are using a sliding window to improve the accuracy the peak detection algorithm.  Rather than find peaks over the entire data set, we use a fixed window length and calculate the average peak distance as the window slides over the time series from beginning to end.  The function gives control over how far to slide the window at each calucation and how big the window should be.  The function returns a list of lists of average peaks from the upper half and lower half of the time series. \n",
    "\n",
    "Parameters \n",
    "* timeseries(pandas dataframe) - dataframe of activity data. index starts at 0 and increases by 1.\n",
    "* threshold(float between [0.,1.]) - Normalized threshold. Only the peaks with amplitude higher than the threshold will be detected.\n",
    "* window_size(int) - size of the sliding window, less than the length of the time series.  If greater, window_size will be set to the length of the time series.\n",
    "* axis(str) - either 'x', 'y', or 'z', corresponding to the axis to check\n",
    "* step(int) - how far to slide the window for each calculation of peak distance.  If step is greater than window_size, the window size will be used as the step value.\n",
    "\n",
    "Returns\n",
    "* dic : 'upper' is upper peak averages, 'lower' is lower peak averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_single_peak_dist(timeseries, threshold=0.8, window_size=500, axis='x', step=100):\n",
    "    if (window_size > timeseries.last_valid_index()):\n",
    "        window_size = timeseries.last_valid_index()\n",
    "    if (axis not in ('x', 'y', 'z')):\n",
    "        raise ValueError('invalid axis value, use x, y, or z')\n",
    "    if (step > window_size):\n",
    "        step = window_size\n",
    "    upper = []\n",
    "    lower = []\n",
    "    ts_flipped = timeseries * -1\n",
    "    for i in np.arange(0, timeseries.index.size - window_size, step):\n",
    "        upper.append(estimate_period(timeseries.iloc[i:i+window_size], threshold, axis=axis))\n",
    "        lower.append(estimate_period(ts_flipped.iloc[i:i+window_size], threshold, axis=axis))\n",
    "    return { 'upper': upper, 'lower': lower, 'threshold': threshold, 'window': window_size }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Choosing the correct window size\n",
    "We get better accuracy with a smaller window size but we cannot go too small, otherwise our peak detection algorithm does not register any peaks.  If the window size is n and our shaplet size is s, n cannot be less than s otherwise we would never catch any consecutive pair of peaks.  Realistically, we would like catch multiple peaks at a time and average their distances together but at a minimum to be gaurenteed to catch a single period, n needs to be at least 2s.  Since we do not know the length of the shaplet before hand, we will experiment by testing a number of window sizes to determine correct size.\n",
    "\n",
    "We will use the default threshold value of 0.8.\n",
    "\n",
    "We will use the smallest window size that is able to get a prediction for at least 95% of the windows.  We will use a fixed starting value at 100 and increment by 100 until we fufill the above condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the initializing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = .99\n",
    "starting_window_size = 100\n",
    "increment_window_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set function to capture to optimal window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_accurate(peak_avgs, accuracy=.99):\n",
    "    return (1 - (peak_avgs.isnull().sum()/len(peak_avgs.index)) > accuracy)\n",
    "    \n",
    "def find_window_size(time_series, upper=True, accuracy=.99, starting_window_size=100, step=100):\n",
    "    window_size = starting_window_size\n",
    "    avg = pd.Series(math.nan)\n",
    "    if upper:\n",
    "        side = 'upper'\n",
    "    else:\n",
    "        side = 'lower'\n",
    "        \n",
    "    while not is_accurate(avg, accuracy):\n",
    "        #print(is_accurate(avg, accuracy))\n",
    "        info = find_single_peak_dist(time_series, window_size=window_size)\n",
    "        avg = pd.Series(info[side])\n",
    "        #print(avg.isnull().sum()/len(avg.index))\n",
    "        window_size += increment_window_size\n",
    "    return { 'window_size':(window_size - increment_window_size), 'avg':avg }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find upper peak window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upper = find_window_size(walking125, accuracy=accuracy, starting_window_size=starting_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper['window_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the lower peak window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower = find_window_size(walking125, upper=False, accuracy=accuracy, starting_window_size=starting_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower['window_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x136779c50>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.close()\n",
    "plt.plot(upper['avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1380796a0>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.close()\n",
    "plt.plot(lower['avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper['avg'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.29166666666667"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower['avg'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms of the averages to show the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x13aad5a90>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.close()\n",
    "plt.hist(upper['avg'].dropna(), bins=15, color='green')\n",
    "plt.xlabel('averages')\n",
    "plt.ylabel('frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x13aad5780>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.close()\n",
    "plt.hist(lower['avg'].dropna(), bins=15, color='red')\n",
    "plt.xlabel('averages')\n",
    "plt.ylabel('frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upper vs lower\n",
    "How do we select?  Discuss at next meeting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shaplet search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a shaplet\n",
    "For now we will randomly select a shaplet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
